{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.pata.org/wp-content/uploads/2014/09/TripAdvisor_Logo-300x119.png)\n",
    "# Predict TripAdvisor Rating\n",
    "## В этом соревновании нам предстоит предсказать рейтинг ресторана в TripAdvisor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "\n",
    "# Загружаем специальный удобный инструмент для разделения датасета:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\n",
    "df_train = pd.read_csv(DATA_DIR+'/main_task.csv')\n",
    "df_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\n",
    "sample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим данные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее по признакам:\n",
    "* City: Город \n",
    "* Cuisine Style: Кухня\n",
    "* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n",
    "* Price Range: Цены в ресторане в 3 категориях\n",
    "* Number of Reviews: Количество отзывов\n",
    "* Reviews: 2 последних отзыва и даты этих отзывов\n",
    "* URL_TA: страница ресторана на 'www.tripadvisor.com' \n",
    "* ID_TA: ID ресторана в TripAdvisor\n",
    "* Rating: Рейтинг ресторана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Prepping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Обработка NAN \n",
    "У наличия пропусков могут быть разные причины, но пропуски нужно либо заполнить, либо исключить из набора полностью. Но с пропусками нужно быть внимательным, **даже отсутствие информации может быть важным признаком!**   \n",
    "По этому перед обработкой NAN лучше вынести информацию о наличии пропуска как отдельный признак "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Обработка признаков\n",
    "Для начала посмотрим какие признаки у нас могут быть категориальными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[](http://)признак City можно считать категориальным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cuisine Style'] = data['Cuisine Style'].fillna('Nothing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cuisin = []\n",
    "for i in data['Cuisine Style']:\n",
    "    i = i.strip(\"[]\")\n",
    "    i = i.replace(\"\\'\", '')\n",
    "    i = i.split(\", \")\n",
    "    list_cuisin.append(i)\n",
    "data['Cuisine Style'] = list_cuisin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://)Создадим новый признак - количество кухонь в ресторане, поработав с Cuisine Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['# of Cuisines'] = data['Cuisine Style'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=[ 'City',], dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем  признак \"Price Range\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price Range'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По описанию 'Price Range' это - Цены в ресторане.  \n",
    "Их можно поставить по возрастанию (значит это не категориальный признак). А это значит, что их можно заменить последовательными числами, например 1,2,3. все же попробуем поработать как с категориальным призгаком\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price Range']=data['Price Range'].fillna('$-$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price Range'] = data['Price Range'].replace(['$-$'], '0').replace(['$'], '1') .replace(['$$ - $$$'], '2').replace(['$$$$'], '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data,columns=['Price Range'],prefix=['prices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отделим даты от текста в Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим функцию по вычленению даты из строки в Reviews\n",
    "import re\n",
    "def get_date (string): \n",
    "    dates = re.findall('\\d+\\/\\d+\\/\\d+', str(string)) # зададим формат распознания даты (регулярные выражения)\n",
    "    return dates # функция возвращает список из дат (строки)\n",
    "data['date'] = data['Reviews'].apply(get_date) # создадим столбец date применив функцию к столбцу Reviews\n",
    "data['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data[data['date'].apply(len)==3] # определяем в df1 какие строки содержат 3 даты (в основном храняться по 2 даты)\n",
    "def change_date(dates): # создаем функцию поиска и корректировки даты\n",
    "    if len(dates)== 3:\n",
    "        if dates == ['29/9/2016', '09/30/2016', '08/25/2016']:\n",
    "            return ['09/29/2016', '09/30/2016', '08/25/2016']\n",
    "        else:\n",
    "            return dates\n",
    "    else:\n",
    "        return dates\n",
    "data['date'] = data['date'].apply(change_date) #применяем функцию к строке с с неправильным форматом даты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для вычесления разницы в датах комментариев создаем столбцы мин и макс дат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем функцию по возврату максимальной даты из dates\n",
    "def to_date_max (dates): \n",
    "    dates = pd.Series ([pd.to_datetime(i, format = '%m/%d/%Y',errors='coerce') for i in dates]) # переводим каждую строку из dates в формат datetime и сохраняем в виде Series\n",
    "    return dates.max() # возвращаем max из Series\n",
    "data['max']=data['date'].apply(to_date_max) # применяем to_date_max к df['date'] и сохраняем в df['max'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем функцию по возврату минимальной даты из dates\n",
    "def to_date_min (dates):\n",
    "    dates = pd.Series ([pd.to_datetime(i, format = '%m/%d/%Y',errors='coerce') for i in dates])\n",
    "    return dates.min()\n",
    "data['min']=data['date'].apply(to_date_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем функцию по возврату разницы min от max \n",
    "data['diff']=(data['max']-data['min']).apply(lambda x: x.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['diff'] = data['diff'].fillna(data['diff'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поработаем с Restaurant_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Restaurant_id.value_counts()\n",
    "# данные говорят о том, что некоторые ID имеют более 1 значения, то есть можно сделать вывод, что это сетевые рестораны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим новый признак chain_restor , для понимания принадлежит ли ресторан к сети. если да, то присваиваем 1. ресторанам с Nan в Restaurant_id присвоим 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_restor = data.Restaurant_id.value_counts()[data.Restaurant_id.value_counts() > 1].index.tolist()\n",
    "data['chain_restor'] = data[data.Restaurant_id.isin(chain_restor)].Restaurant_id.apply(lambda x: 1)\n",
    "data.chain_restor=data['chain_restor'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.chain_restor.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['max', 'min'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_rev = []\n",
    "for i in data.date:\n",
    "    len_rev.append(len(i))\n",
    "data['# of reviews'] = len_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['diff'] = data['diff'].apply(lambda x: 0 if x%1 != 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsa = set()\n",
    "for i in data['Cuisine Style']:\n",
    "    for q in i:\n",
    "        dsa.add(q)\n",
    "# Creating columns for each cuisine\n",
    "for i in dsa:\n",
    "    data[i] = 0\n",
    "\n",
    "# For each cuisine we are adding 1 to the respective column\n",
    "for index, row in data.iterrows():\n",
    "    for i in row['Cuisine Style']:\n",
    "        data[i][index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.columns:\n",
    "    if data[i].dtype == 'object':\n",
    "        data = data.drop([i], axis=1)\n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь выделим тестовую часть\n",
    "train_data = data.query('sample == 1').drop(['sample'], axis=1)\n",
    "test_data = data.query('sample == 0').drop(['sample'], axis=1)\n",
    "\n",
    "y = train_data.Rating.values            # наш таргет\n",
    "X = train_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \n",
    "Это поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n",
    "# выделим 20% данных на валидацию (параметр test_size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем\n",
    "test_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "Сам ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\n",
    "model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель на тестовом наборе данных\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Если все устраевает - готовим Submission на кагл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['Rating'] = predict_submission\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
